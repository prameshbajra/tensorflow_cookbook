{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:24.901565Z",
     "start_time": "2019-04-11T11:29:24.896811Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:24.972733Z",
     "start_time": "2019-04-11T11:29:24.905319Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.011449Z",
     "start_time": "2019-04-11T11:29:24.975354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85262768 0.88167145 0.99445685 1.05137431 0.90771676 0.91995774\n",
      " 1.14109902 1.03899296 1.00233132 1.13587767 1.0838863  0.86758031\n",
      " 0.9692499  1.04441274 0.84454501 0.99914171 0.85841952 1.00887461\n",
      " 0.96971001 1.1614556  1.04798028 0.98198129 0.91311325 0.91243881\n",
      " 0.92936964 1.02317447 0.84519766 0.82465338 0.99829788 0.89103206\n",
      " 0.80926742 0.98030967 0.85888595 1.11005345 1.20184816 1.20073016\n",
      " 0.96526202 1.16326599 0.94558679 1.02068371 0.85260811 0.89835098\n",
      " 1.13160795 0.8009209  0.9336862  0.92089028 1.06891666 0.99413041\n",
      " 0.87977856 1.27400341 1.08381898 1.25126248 1.11523621 0.99130929\n",
      " 0.89788344 1.00218918 1.07286407 0.98297773 0.99982325 1.11823235\n",
      " 0.96429342 1.21608488 0.99188825 0.96478594 1.05488851 1.04765193\n",
      " 1.06706657 0.99538958 0.79805853 1.13222605 1.01848997 0.9393722\n",
      " 1.0201721  0.99939698 0.82112176 1.07320904 0.98496223 1.03178751\n",
      " 0.83598558 1.00602751 0.95062738 0.73209187 1.05739404 0.86088665\n",
      " 1.03167664 1.02210511 0.91555065 0.77824106 0.88234866 1.0834944\n",
      " 0.85982601 0.88531406 0.89369153 0.90323654 0.93435322 0.94454291\n",
      " 0.99418325 0.99156473 1.06733448 0.97469096] \n",
      "\n",
      "\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10, 100)\n",
    "\n",
    "print(f\"{x_vals} \\n\\n\\n {y_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.068623Z",
     "start_time": "2019-04-11T11:29:25.015178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(1,), dtype=float32) \n",
      "\n",
      "Tensor(\"Placeholder_1:0\", shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "\n",
    "print(f\"{x_data} \\n\\n{y_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.143363Z",
     "start_time": "2019-04-11T11:29:25.070132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.Variable(tf.random_normal(shape = [1]))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.357315Z",
     "start_time": "2019-04-11T11:29:25.145172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul:0' shape=(1,) dtype=float32>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.multiply(x_data, A)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.416563Z",
     "start_time": "2019-04-11T11:29:25.360300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Square:0' shape=(1,) dtype=float32>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.square(output - y_target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.489003Z",
     "start_time": "2019-04-11T11:29:25.419044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7efe49657f60> \n",
      "\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "print(f\"{optimizer} \\n\\n{train_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:25.539887Z",
     "start_time": "2019-04-11T11:29:25.495723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.259331Z",
     "start_time": "2019-04-11T11:29:25.542293Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 A = [1.1362834]\n",
      "Loss = [78.67717]\n",
      "Step #10 A = [2.7532492]\n",
      "Loss = [57.343346]\n",
      "Step #15 A = [4.045195]\n",
      "Loss = [37.17649]\n",
      "Step #20 A = [5.109506]\n",
      "Loss = [19.90834]\n",
      "Step #25 A = [6.0106063]\n",
      "Loss = [15.803658]\n",
      "Step #30 A = [6.71966]\n",
      "Loss = [19.8792]\n",
      "Step #35 A = [7.310409]\n",
      "Loss = [11.806816]\n",
      "Step #40 A = [7.828473]\n",
      "Loss = [1.2914011]\n",
      "Step #45 A = [8.206212]\n",
      "Loss = [9.421737]\n",
      "Step #50 A = [8.615001]\n",
      "Loss = [10.860011]\n",
      "Step #55 A = [8.890573]\n",
      "Loss = [5.855558]\n",
      "Step #60 A = [9.151961]\n",
      "Loss = [0.0548722]\n",
      "Step #65 A = [9.280429]\n",
      "Loss = [0.12794885]\n",
      "Step #70 A = [9.375794]\n",
      "Loss = [0.49036428]\n",
      "Step #75 A = [9.402639]\n",
      "Loss = [0.00660376]\n",
      "Step #80 A = [9.611831]\n",
      "Loss = [3.257575]\n",
      "Step #85 A = [9.760586]\n",
      "Loss = [0.2862922]\n",
      "Step #90 A = [9.775428]\n",
      "Loss = [0.81344306]\n",
      "Step #95 A = [9.750672]\n",
      "Loss = [0.81634426]\n",
      "Step #100 A = [9.943249]\n",
      "Loss = [1.5210835]\n",
      "Step #105 A = [10.133821]\n",
      "Loss = [0.89017344]\n",
      "Step #110 A = [10.186675]\n",
      "Loss = [0.00963254]\n",
      "Step #115 A = [10.047805]\n",
      "Loss = [1.8771244]\n",
      "Step #120 A = [9.954981]\n",
      "Loss = [0.01004036]\n",
      "Step #125 A = [9.818807]\n",
      "Loss = [3.203161]\n",
      "Step #130 A = [9.849045]\n",
      "Loss = [0.05433024]\n",
      "Step #135 A = [9.893475]\n",
      "Loss = [1.6794417]\n",
      "Step #140 A = [9.842991]\n",
      "Loss = [0.24893588]\n",
      "Step #145 A = [9.737094]\n",
      "Loss = [2.8834598]\n",
      "Step #150 A = [9.78339]\n",
      "Loss = [0.05441163]\n",
      "Step #155 A = [9.913028]\n",
      "Loss = [1.3014497]\n",
      "Step #160 A = [9.961092]\n",
      "Loss = [1.2052889]\n",
      "Step #165 A = [9.98315]\n",
      "Loss = [1.4811842]\n",
      "Step #170 A = [9.974252]\n",
      "Loss = [1.6721283]\n",
      "Step #175 A = [9.941388]\n",
      "Loss = [0.36981338]\n",
      "Step #180 A = [10.020167]\n",
      "Loss = [7.0985856]\n",
      "Step #185 A = [10.037746]\n",
      "Loss = [0.7075675]\n",
      "Step #190 A = [10.069411]\n",
      "Loss = [0.01254987]\n",
      "Step #195 A = [10.066365]\n",
      "Loss = [0.2981665]\n",
      "Step #200 A = [10.276961]\n",
      "Loss = [0.45926443]\n",
      "Step #205 A = [10.340321]\n",
      "Loss = [0.00049975]\n",
      "Step #210 A = [10.256565]\n",
      "Loss = [2.0692616]\n",
      "Step #215 A = [10.242699]\n",
      "Loss = [1.6047603]\n",
      "Step #220 A = [10.309798]\n",
      "Loss = [0.7668288]\n",
      "Step #225 A = [10.257233]\n",
      "Loss = [0.54065496]\n",
      "Step #230 A = [10.089515]\n",
      "Loss = [0.8684999]\n",
      "Step #235 A = [10.1873865]\n",
      "Loss = [0.03110659]\n",
      "Step #240 A = [10.264489]\n",
      "Loss = [0.34766817]\n",
      "Step #245 A = [10.271714]\n",
      "Loss = [0.52158993]\n",
      "Step #250 A = [10.208464]\n",
      "Loss = [1.4681439]\n",
      "Step #255 A = [10.145319]\n",
      "Loss = [0.6995267]\n",
      "Step #260 A = [10.224699]\n",
      "Loss = [1.2752111]\n",
      "Step #265 A = [10.209698]\n",
      "Loss = [0.01463322]\n",
      "Step #270 A = [9.996584]\n",
      "Loss = [6.2918167]\n",
      "Step #275 A = [9.927362]\n",
      "Loss = [0.5778004]\n",
      "Step #280 A = [9.883065]\n",
      "Loss = [1.2682356]\n",
      "Step #285 A = [9.983156]\n",
      "Loss = [0.02813826]\n",
      "Step #290 A = [9.984755]\n",
      "Loss = [0.25828633]\n",
      "Step #295 A = [9.99413]\n",
      "Loss = [3.6560347]\n",
      "Step #300 A = [9.9727125]\n",
      "Loss = [7.284917]\n",
      "Step #305 A = [10.049491]\n",
      "Loss = [3.0560079]\n",
      "Step #310 A = [10.094765]\n",
      "Loss = [0.10804749]\n",
      "Step #315 A = [9.839712]\n",
      "Loss = [0.0499042]\n",
      "Step #320 A = [9.87454]\n",
      "Loss = [0.00326273]\n",
      "Step #325 A = [9.968299]\n",
      "Loss = [0.6409543]\n",
      "Step #330 A = [9.873997]\n",
      "Loss = [4.03053]\n",
      "Step #335 A = [10.095113]\n",
      "Loss = [2.173334]\n",
      "Step #340 A = [10.1642]\n",
      "Loss = [0.15958188]\n",
      "Step #345 A = [10.276204]\n",
      "Loss = [1.389346]\n",
      "Step #350 A = [10.211096]\n",
      "Loss = [0.03752554]\n",
      "Step #355 A = [10.240398]\n",
      "Loss = [1.4512205]\n",
      "Step #360 A = [10.256587]\n",
      "Loss = [0.9159636]\n",
      "Step #365 A = [10.293412]\n",
      "Loss = [0.0461394]\n",
      "Step #370 A = [10.22741]\n",
      "Loss = [4.1640863]\n",
      "Step #375 A = [10.182548]\n",
      "Loss = [3.4040647]\n",
      "Step #380 A = [10.176097]\n",
      "Loss = [0.74183685]\n",
      "Step #385 A = [10.249838]\n",
      "Loss = [1.8051285]\n",
      "Step #390 A = [10.15632]\n",
      "Loss = [7.334463]\n",
      "Step #395 A = [10.0971775]\n",
      "Loss = [1.5894588]\n",
      "Step #400 A = [10.247505]\n",
      "Loss = [2.4005172]\n",
      "Step #405 A = [10.236487]\n",
      "Loss = [0.39435557]\n",
      "Step #410 A = [10.278765]\n",
      "Loss = [1.3729132]\n",
      "Step #415 A = [10.246897]\n",
      "Loss = [2.687043]\n",
      "Step #420 A = [10.235045]\n",
      "Loss = [1.8388548]\n",
      "Step #425 A = [10.183582]\n",
      "Loss = [0.0054988]\n",
      "Step #430 A = [10.135113]\n",
      "Loss = [2.1763322]\n",
      "Step #435 A = [10.144652]\n",
      "Loss = [1.6042868]\n",
      "Step #440 A = [10.212801]\n",
      "Loss = [0.42206198]\n",
      "Step #445 A = [10.150368]\n",
      "Loss = [1.0023245]\n",
      "Step #450 A = [10.246773]\n",
      "Loss = [0.7565464]\n",
      "Step #455 A = [10.205198]\n",
      "Loss = [0.8223611]\n",
      "Step #460 A = [10.222488]\n",
      "Loss = [1.6487159]\n",
      "Step #465 A = [10.354595]\n",
      "Loss = [2.1346617]\n",
      "Step #470 A = [10.270999]\n",
      "Loss = [0.08699129]\n",
      "Step #475 A = [10.36097]\n",
      "Loss = [0.00179512]\n",
      "Step #480 A = [10.468224]\n",
      "Loss = [0.35505086]\n",
      "Step #485 A = [10.302833]\n",
      "Loss = [0.24337637]\n",
      "Step #490 A = [10.255813]\n",
      "Loss = [0.6188673]\n",
      "Step #495 A = [10.194193]\n",
      "Loss = [0.41853783]\n",
      "Step #500 A = [10.223796]\n",
      "Loss = [1.436333]\n",
      "Step #505 A = [10.145211]\n",
      "Loss = [1.5919535]\n",
      "Step #510 A = [10.083755]\n",
      "Loss = [0.86297524]\n",
      "Step #515 A = [10.096631]\n",
      "Loss = [0.01444051]\n",
      "Step #520 A = [10.100322]\n",
      "Loss = [0.32429546]\n",
      "Step #525 A = [9.925664]\n",
      "Loss = [0.87749064]\n",
      "Step #530 A = [9.995482]\n",
      "Loss = [0.05158497]\n",
      "Step #535 A = [9.9275465]\n",
      "Loss = [0.5781035]\n",
      "Step #540 A = [10.159825]\n",
      "Loss = [3.5791523]\n",
      "Step #545 A = [10.068664]\n",
      "Loss = [0.08481614]\n",
      "Step #550 A = [10.069626]\n",
      "Loss = [0.00866771]\n",
      "Step #555 A = [10.091781]\n",
      "Loss = [0.16929457]\n",
      "Step #560 A = [10.040619]\n",
      "Loss = [0.07469611]\n",
      "Step #565 A = [10.056307]\n",
      "Loss = [1.8314909]\n",
      "Step #570 A = [10.030341]\n",
      "Loss = [1.9314302]\n",
      "Step #575 A = [9.972404]\n",
      "Loss = [1.7620698]\n",
      "Step #580 A = [9.844704]\n",
      "Loss = [0.16358477]\n",
      "Step #585 A = [9.983831]\n",
      "Loss = [0.10444051]\n",
      "Step #590 A = [10.068072]\n",
      "Loss = [2.2215574]\n",
      "Step #595 A = [10.2341]\n",
      "Loss = [0.6499354]\n",
      "Step #600 A = [10.383893]\n",
      "Loss = [0.45107263]\n",
      "Step #605 A = [10.323782]\n",
      "Loss = [0.24297945]\n",
      "Step #610 A = [10.401856]\n",
      "Loss = [0.00672365]\n",
      "Step #615 A = [10.292116]\n",
      "Loss = [3.8174767]\n",
      "Step #620 A = [10.210431]\n",
      "Loss = [0.01545144]\n",
      "Step #625 A = [10.182813]\n",
      "Loss = [0.01527248]\n",
      "Step #630 A = [10.03689]\n",
      "Loss = [6.5473733]\n",
      "Step #635 A = [10.028786]\n",
      "Loss = [3.871986]\n",
      "Step #640 A = [10.088554]\n",
      "Loss = [2.0235758]\n",
      "Step #645 A = [10.08728]\n",
      "Loss = [0.36663976]\n",
      "Step #650 A = [9.862071]\n",
      "Loss = [0.27681148]\n",
      "Step #655 A = [9.98026]\n",
      "Loss = [0.27884832]\n",
      "Step #660 A = [10.161332]\n",
      "Loss = [3.1568935]\n",
      "Step #665 A = [10.041177]\n",
      "Loss = [0.06193385]\n",
      "Step #670 A = [10.107547]\n",
      "Loss = [0.5939248]\n",
      "Step #675 A = [10.054928]\n",
      "Loss = [0.53578264]\n",
      "Step #680 A = [9.87273]\n",
      "Loss = [1.6610307]\n",
      "Step #685 A = [9.944795]\n",
      "Loss = [0.26580915]\n",
      "Step #690 A = [9.985773]\n",
      "Loss = [0.00530549]\n",
      "Step #695 A = [9.8992405]\n",
      "Loss = [0.5733753]\n",
      "Step #700 A = [9.827564]\n",
      "Loss = [6.3521667]\n",
      "Step #705 A = [9.791316]\n",
      "Loss = [1.9318331]\n",
      "Step #710 A = [9.842901]\n",
      "Loss = [0.00061979]\n",
      "Step #715 A = [10.035745]\n",
      "Loss = [1.3265755]\n",
      "Step #720 A = [10.024331]\n",
      "Loss = [0.00362722]\n",
      "Step #725 A = [10.062855]\n",
      "Loss = [1.1907463]\n",
      "Step #730 A = [10.104074]\n",
      "Loss = [0.00461322]\n",
      "Step #735 A = [10.0387335]\n",
      "Loss = [5.6991717e-05]\n",
      "Step #740 A = [10.03355]\n",
      "Loss = [0.00324228]\n",
      "Step #745 A = [10.0768385]\n",
      "Loss = [0.00464982]\n",
      "Step #750 A = [10.251332]\n",
      "Loss = [0.40879762]\n",
      "Step #755 A = [10.118163]\n",
      "Loss = [0.05443922]\n",
      "Step #760 A = [10.183216]\n",
      "Loss = [1.940921]\n",
      "Step #765 A = [10.042846]\n",
      "Loss = [1.9808986]\n",
      "Step #770 A = [10.03798]\n",
      "Loss = [0.7732626]\n",
      "Step #775 A = [9.970278]\n",
      "Loss = [0.5386485]\n",
      "Step #780 A = [9.988463]\n",
      "Loss = [2.6219344]\n",
      "Step #785 A = [10.009064]\n",
      "Loss = [0.9205402]\n",
      "Step #790 A = [10.057753]\n",
      "Loss = [2.0291471]\n",
      "Step #795 A = [9.925849]\n",
      "Loss = [0.02429738]\n",
      "Step #800 A = [9.752224]\n",
      "Loss = [0.00387164]\n",
      "Step #805 A = [9.800741]\n",
      "Loss = [0.9677291]\n",
      "Step #810 A = [9.8324175]\n",
      "Loss = [1.8215536]\n",
      "Step #815 A = [9.78395]\n",
      "Loss = [0.06820349]\n",
      "Step #820 A = [9.8007965]\n",
      "Loss = [0.01262006]\n",
      "Step #825 A = [9.941923]\n",
      "Loss = [2.1073616]\n",
      "Step #830 A = [9.926415]\n",
      "Loss = [0.00633151]\n",
      "Step #835 A = [9.991213]\n",
      "Loss = [0.13361916]\n",
      "Step #840 A = [9.983751]\n",
      "Loss = [0.25925657]\n",
      "Step #845 A = [10.001557]\n",
      "Loss = [0.00290333]\n",
      "Step #850 A = [10.083981]\n",
      "Loss = [1.9664931]\n",
      "Step #855 A = [9.998103]\n",
      "Loss = [1.3230673]\n",
      "Step #860 A = [9.980888]\n",
      "Loss = [0.03958293]\n",
      "Step #865 A = [9.970995]\n",
      "Loss = [0.00096687]\n",
      "Step #870 A = [10.075453]\n",
      "Loss = [4.6607165]\n",
      "Step #875 A = [10.013468]\n",
      "Loss = [0.02464408]\n",
      "Step #880 A = [10.037117]\n",
      "Loss = [0.00349159]\n",
      "Step #885 A = [10.009116]\n",
      "Loss = [6.370731]\n",
      "Step #890 A = [10.143166]\n",
      "Loss = [0.6286573]\n",
      "Step #895 A = [10.126983]\n",
      "Loss = [5.360477]\n",
      "Step #900 A = [10.236825]\n",
      "Loss = [0.77204543]\n",
      "Step #905 A = [10.052652]\n",
      "Loss = [0.8026945]\n",
      "Step #910 A = [10.217484]\n",
      "Loss = [1.8792967]\n",
      "Step #915 A = [10.149297]\n",
      "Loss = [1.7393994]\n",
      "Step #920 A = [10.106057]\n",
      "Loss = [0.25012305]\n",
      "Step #925 A = [9.998213]\n",
      "Loss = [1.7430261]\n",
      "Step #930 A = [9.921569]\n",
      "Loss = [4.2661653]\n",
      "Step #935 A = [10.1228485]\n",
      "Loss = [0.82107127]\n",
      "Step #940 A = [10.2093525]\n",
      "Loss = [1.678122]\n",
      "Step #945 A = [10.024326]\n",
      "Loss = [1.3498665]\n",
      "Step #950 A = [9.973729]\n",
      "Loss = [0.00710409]\n",
      "Step #955 A = [9.905702]\n",
      "Loss = [0.14514613]\n",
      "Step #960 A = [9.998286]\n",
      "Loss = [0.12182495]\n",
      "Step #965 A = [10.121501]\n",
      "Loss = [0.35210544]\n",
      "Step #970 A = [10.190856]\n",
      "Loss = [0.2638549]\n",
      "Step #975 A = [10.196943]\n",
      "Loss = [1.7051222]\n",
      "Step #980 A = [10.007161]\n",
      "Loss = [2.6337178]\n",
      "Step #985 A = [10.025532]\n",
      "Loss = [0.04448014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #990 A = [9.946629]\n",
      "Loss = [0.02772228]\n",
      "Step #995 A = [10.012811]\n",
      "Loss = [0.04613489]\n",
      "Step #1000 A = [10.070833]\n",
      "Loss = [0.00015015]\n",
      "Step #1005 A = [10.084686]\n",
      "Loss = [1.4269259]\n",
      "Step #1010 A = [10.131595]\n",
      "Loss = [0.1342411]\n",
      "Step #1015 A = [10.13048]\n",
      "Loss = [0.660336]\n",
      "Step #1020 A = [10.15955]\n",
      "Loss = [0.48778725]\n",
      "Step #1025 A = [10.065473]\n",
      "Loss = [2.5135252]\n",
      "Step #1030 A = [10.048812]\n",
      "Loss = [0.3913179]\n",
      "Step #1035 A = [10.0490675]\n",
      "Loss = [0.31959966]\n",
      "Step #1040 A = [10.13398]\n",
      "Loss = [0.42850885]\n",
      "Step #1045 A = [10.115952]\n",
      "Loss = [0.6353761]\n",
      "Step #1050 A = [10.212216]\n",
      "Loss = [0.28698045]\n",
      "Step #1055 A = [10.142406]\n",
      "Loss = [2.2007651]\n",
      "Step #1060 A = [10.24066]\n",
      "Loss = [2.0185432]\n",
      "Step #1065 A = [10.308953]\n",
      "Loss = [0.13527386]\n",
      "Step #1070 A = [10.240759]\n",
      "Loss = [0.53599066]\n",
      "Step #1075 A = [10.2461405]\n",
      "Loss = [2.5175245]\n",
      "Step #1080 A = [10.178052]\n",
      "Loss = [3.524328]\n",
      "Step #1085 A = [9.942353]\n",
      "Loss = [0.00556064]\n",
      "Step #1090 A = [9.9898815]\n",
      "Loss = [0.43896616]\n",
      "Step #1095 A = [10.026724]\n",
      "Loss = [2.9978435]\n",
      "Step #1100 A = [10.113042]\n",
      "Loss = [0.5967077]\n"
     ]
    }
   ],
   "source": [
    "loss_stochastic = []\n",
    "for i in range(1100):\n",
    "    rand_index = np.random.choice(100)\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1) % 5 == 0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        temp_loss = sess.run(\n",
    "            loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        print('Loss = ' + str(temp_loss))\n",
    "        loss_stochastic.append(temp_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.263465Z",
     "start_time": "2019-04-11T11:29:26.261097Z"
    }
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.305656Z",
     "start_time": "2019-04-11T11:29:26.265127Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.344482Z",
     "start_time": "2019-04-11T11:29:26.308200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.04386483 0.94751924 0.92763887 0.94813709 1.04983703 0.79512709\n",
      " 1.11567955 0.86773087 0.86826927 1.12356358 0.93954345 0.99347286\n",
      " 0.93960077 0.97137462 0.95190196 1.08333352 1.01035158 1.0747164\n",
      " 0.9351515  1.09037459 1.00210633 1.08655754 0.82402943 1.03139664\n",
      " 0.97195011 0.88920104 0.98137286 0.98371609 1.0360076  0.98493076\n",
      " 1.05741915 1.00036225 1.07166695 0.91819928 0.86451379 1.05663256\n",
      " 1.06768349 0.92545012 1.01048305 1.04211152 0.95961206 1.07872772\n",
      " 0.98199248 0.9588467  0.98556324 0.9880849  0.93128    1.13090664\n",
      " 1.08580759 0.98230958 0.96554591 0.94855308 1.06529747 1.03866705\n",
      " 1.03981426 1.04494373 1.10222344 0.97539393 0.99074363 0.90126121\n",
      " 1.01146989 0.90793201 0.96635971 0.91917036 1.15400947 0.85999583\n",
      " 1.21024682 1.18345221 0.960235   1.16886175 1.0866977  1.00805381\n",
      " 0.82706284 1.01090301 1.03967965 1.02073807 1.09798786 0.99365289\n",
      " 0.88416934 0.93960152 1.04143492 1.17787027 0.865344   1.03437384\n",
      " 0.82907125 0.95261161 1.17753491 0.93897254 0.96034173 0.95960246\n",
      " 0.93058216 0.99045903 0.91301705 0.98321009 1.09067848 1.06669607\n",
      " 1.03775551 1.0144317  0.89900448 0.96183251] \n",
      "\n",
      " [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10]\n"
     ]
    }
   ],
   "source": [
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10, 100)\n",
    "\n",
    "print(f\"{x_vals} \\n\\n {y_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.410276Z",
     "start_time": "2019-04-11T11:29:26.346632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 1), dtype=float32) \n",
      "\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_data = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "y_target = tf.placeholder(dtype=tf.float32, shape=(None, 1))\n",
    "\n",
    "print(f\"{x_data} \\n\\n{y_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.602569Z",
     "start_time": "2019-04-11T11:29:26.412261Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.651119Z",
     "start_time": "2019-04-11T11:29:26.605720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 1) dtype=float32_ref>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.699943Z",
     "start_time": "2019-04-11T11:29:26.653493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.matmul(x_data, A)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.738904Z",
     "start_time": "2019-04-11T11:29:26.701969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.square(output - y_target))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.813227Z",
     "start_time": "2019-04-11T11:29:26.740775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:26.911696Z",
     "start_time": "2019-04-11T11:29:26.816374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x7efe48db4128> \n",
      "\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "print(f\"{optimizer} \\n\\n{train_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:27.711647Z",
     "start_time": "2019-04-11T11:29:26.914304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 A = [[1.9762037]]\n",
      "Loss = 65.04704\n",
      "Step #10 A = [[3.447663]]\n",
      "Loss = 42.83485\n",
      "Step #15 A = [[4.6483803]]\n",
      "Loss = 29.2382\n",
      "Step #20 A = [[5.6298723]]\n",
      "Loss = 19.21988\n",
      "Step #25 A = [[6.427499]]\n",
      "Loss = 12.641296\n",
      "Step #30 A = [[7.0709076]]\n",
      "Loss = 7.8702865\n",
      "Step #35 A = [[7.5960264]]\n",
      "Loss = 5.804594\n",
      "Step #40 A = [[8.040681]]\n",
      "Loss = 4.952919\n",
      "Step #45 A = [[8.38126]]\n",
      "Loss = 3.1836345\n",
      "Step #50 A = [[8.664085]]\n",
      "Loss = 1.9512146\n",
      "Step #55 A = [[8.904412]]\n",
      "Loss = 1.782226\n",
      "Step #60 A = [[9.117384]]\n",
      "Loss = 2.2044964\n",
      "Step #65 A = [[9.291586]]\n",
      "Loss = 1.7807995\n",
      "Step #70 A = [[9.389276]]\n",
      "Loss = 0.83126295\n",
      "Step #75 A = [[9.492998]]\n",
      "Loss = 0.84304935\n",
      "Step #80 A = [[9.564001]]\n",
      "Loss = 1.0761534\n",
      "Step #85 A = [[9.636509]]\n",
      "Loss = 0.7534602\n",
      "Step #90 A = [[9.707773]]\n",
      "Loss = 0.5740959\n",
      "Step #95 A = [[9.750773]]\n",
      "Loss = 0.7016996\n",
      "Step #100 A = [[9.774003]]\n",
      "Loss = 0.7104515\n",
      "Step #105 A = [[9.810991]]\n",
      "Loss = 0.8631689\n",
      "Step #110 A = [[9.826466]]\n",
      "Loss = 0.3982454\n",
      "Step #115 A = [[9.852684]]\n",
      "Loss = 0.72056687\n",
      "Step #120 A = [[9.879755]]\n",
      "Loss = 0.8328079\n",
      "Step #125 A = [[9.8802]]\n",
      "Loss = 0.44998592\n",
      "Step #130 A = [[9.859142]]\n",
      "Loss = 0.92500293\n",
      "Step #135 A = [[9.869645]]\n",
      "Loss = 0.6465475\n",
      "Step #140 A = [[9.873429]]\n",
      "Loss = 0.64047754\n",
      "Step #145 A = [[9.858214]]\n",
      "Loss = 0.7366556\n",
      "Step #150 A = [[9.876486]]\n",
      "Loss = 0.66047436\n",
      "Step #155 A = [[9.8710785]]\n",
      "Loss = 0.8009664\n",
      "Step #160 A = [[9.880424]]\n",
      "Loss = 0.7637852\n",
      "Step #165 A = [[9.885051]]\n",
      "Loss = 0.6244754\n",
      "Step #170 A = [[9.877158]]\n",
      "Loss = 0.80890846\n",
      "Step #175 A = [[9.8990135]]\n",
      "Loss = 0.5921496\n",
      "Step #180 A = [[9.909993]]\n",
      "Loss = 0.7163637\n",
      "Step #185 A = [[9.889781]]\n",
      "Loss = 0.9344231\n",
      "Step #190 A = [[9.899541]]\n",
      "Loss = 0.40589786\n",
      "Step #195 A = [[9.907648]]\n",
      "Loss = 0.7972975\n",
      "Step #200 A = [[9.927506]]\n",
      "Loss = 1.0273225\n",
      "Step #205 A = [[9.94249]]\n",
      "Loss = 0.8445358\n",
      "Step #210 A = [[9.918417]]\n",
      "Loss = 0.8702959\n",
      "Step #215 A = [[9.918694]]\n",
      "Loss = 0.7041141\n",
      "Step #220 A = [[9.934646]]\n",
      "Loss = 1.3077314\n",
      "Step #225 A = [[9.957903]]\n",
      "Loss = 0.77139413\n",
      "Step #230 A = [[9.9524355]]\n",
      "Loss = 0.47700915\n",
      "Step #235 A = [[9.926087]]\n",
      "Loss = 0.41061276\n",
      "Step #240 A = [[9.934789]]\n",
      "Loss = 0.6741987\n",
      "Step #245 A = [[9.938543]]\n",
      "Loss = 0.87423766\n",
      "Step #250 A = [[9.91811]]\n",
      "Loss = 0.7591303\n",
      "Step #255 A = [[9.917412]]\n",
      "Loss = 0.6520648\n",
      "Step #260 A = [[9.943675]]\n",
      "Loss = 0.62296593\n",
      "Step #265 A = [[9.950266]]\n",
      "Loss = 1.1024247\n",
      "Step #270 A = [[9.928423]]\n",
      "Loss = 0.41487962\n",
      "Step #275 A = [[9.935428]]\n",
      "Loss = 0.703059\n",
      "Step #280 A = [[9.927164]]\n",
      "Loss = 0.46144277\n",
      "Step #285 A = [[9.921142]]\n",
      "Loss = 0.31156665\n",
      "Step #290 A = [[9.9169445]]\n",
      "Loss = 0.46049818\n",
      "Step #295 A = [[9.945172]]\n",
      "Loss = 0.2188021\n",
      "Step #300 A = [[9.95102]]\n",
      "Loss = 0.42450875\n",
      "Step #305 A = [[9.9230175]]\n",
      "Loss = 1.0781221\n",
      "Step #310 A = [[9.906106]]\n",
      "Loss = 0.63491565\n",
      "Step #315 A = [[9.904363]]\n",
      "Loss = 0.67434764\n",
      "Step #320 A = [[9.925996]]\n",
      "Loss = 0.81407374\n",
      "Step #325 A = [[9.930049]]\n",
      "Loss = 0.99615955\n",
      "Step #330 A = [[9.936301]]\n",
      "Loss = 1.0244967\n",
      "Step #335 A = [[9.946159]]\n",
      "Loss = 0.48435324\n",
      "Step #340 A = [[9.956036]]\n",
      "Loss = 1.0085741\n",
      "Step #345 A = [[9.94787]]\n",
      "Loss = 0.4445727\n",
      "Step #350 A = [[9.951601]]\n",
      "Loss = 0.8938176\n",
      "Step #355 A = [[9.962527]]\n",
      "Loss = 0.88931257\n",
      "Step #360 A = [[9.979591]]\n",
      "Loss = 0.6252635\n",
      "Step #365 A = [[9.9668]]\n",
      "Loss = 0.761428\n",
      "Step #370 A = [[9.973755]]\n",
      "Loss = 0.36304814\n",
      "Step #375 A = [[9.976001]]\n",
      "Loss = 0.6326779\n",
      "Step #380 A = [[9.943593]]\n",
      "Loss = 0.55969703\n",
      "Step #385 A = [[9.928966]]\n",
      "Loss = 0.9879036\n",
      "Step #390 A = [[9.906282]]\n",
      "Loss = 0.76637924\n",
      "Step #395 A = [[9.912287]]\n",
      "Loss = 0.59920037\n",
      "Step #400 A = [[9.923096]]\n",
      "Loss = 0.7744056\n",
      "Step #405 A = [[9.937461]]\n",
      "Loss = 0.69631505\n",
      "Step #410 A = [[9.961219]]\n",
      "Loss = 0.7637352\n",
      "Step #415 A = [[9.94282]]\n",
      "Loss = 0.6827884\n",
      "Step #420 A = [[9.945802]]\n",
      "Loss = 0.6888153\n",
      "Step #425 A = [[9.918731]]\n",
      "Loss = 0.6238855\n",
      "Step #430 A = [[9.898721]]\n",
      "Loss = 1.1466461\n",
      "Step #435 A = [[9.892815]]\n",
      "Loss = 0.96399796\n",
      "Step #440 A = [[9.900472]]\n",
      "Loss = 1.0043488\n",
      "Step #445 A = [[9.909641]]\n",
      "Loss = 0.63810754\n",
      "Step #450 A = [[9.92731]]\n",
      "Loss = 0.56314015\n",
      "Step #455 A = [[9.905928]]\n",
      "Loss = 0.6702981\n",
      "Step #460 A = [[9.903959]]\n",
      "Loss = 0.66817844\n",
      "Step #465 A = [[9.936115]]\n",
      "Loss = 0.7063571\n",
      "Step #470 A = [[9.948037]]\n",
      "Loss = 0.7450719\n",
      "Step #475 A = [[9.943312]]\n",
      "Loss = 0.8385418\n",
      "Step #480 A = [[9.955644]]\n",
      "Loss = 0.9516853\n",
      "Step #485 A = [[9.963158]]\n",
      "Loss = 0.6889962\n",
      "Step #490 A = [[9.942076]]\n",
      "Loss = 1.1582596\n",
      "Step #495 A = [[9.943409]]\n",
      "Loss = 0.8849268\n",
      "Step #500 A = [[9.906526]]\n",
      "Loss = 0.63608253\n",
      "Step #505 A = [[9.91793]]\n",
      "Loss = 0.42394766\n",
      "Step #510 A = [[9.933566]]\n",
      "Loss = 0.8426328\n",
      "Step #515 A = [[9.924981]]\n",
      "Loss = 0.75015384\n",
      "Step #520 A = [[9.94345]]\n",
      "Loss = 0.6419935\n",
      "Step #525 A = [[9.927466]]\n",
      "Loss = 0.956509\n",
      "Step #530 A = [[9.922295]]\n",
      "Loss = 0.54380834\n",
      "Step #535 A = [[9.930579]]\n",
      "Loss = 0.6955682\n",
      "Step #540 A = [[9.950939]]\n",
      "Loss = 0.98007905\n",
      "Step #545 A = [[9.94462]]\n",
      "Loss = 0.53091705\n",
      "Step #550 A = [[9.958641]]\n",
      "Loss = 0.8516509\n",
      "Step #555 A = [[9.937692]]\n",
      "Loss = 1.0229591\n",
      "Step #560 A = [[9.917189]]\n",
      "Loss = 0.59233123\n",
      "Step #565 A = [[9.912916]]\n",
      "Loss = 0.89000434\n",
      "Step #570 A = [[9.922105]]\n",
      "Loss = 0.5959755\n",
      "Step #575 A = [[9.924783]]\n",
      "Loss = 0.8650362\n",
      "Step #580 A = [[9.929167]]\n",
      "Loss = 0.6182885\n",
      "Step #585 A = [[9.942941]]\n",
      "Loss = 0.50559866\n",
      "Step #590 A = [[9.960017]]\n",
      "Loss = 0.67863953\n",
      "Step #595 A = [[9.945225]]\n",
      "Loss = 0.45580235\n",
      "Step #600 A = [[9.969891]]\n",
      "Loss = 0.7779224\n",
      "Step #605 A = [[9.9556055]]\n",
      "Loss = 0.7069365\n",
      "Step #610 A = [[9.927097]]\n",
      "Loss = 0.87724745\n",
      "Step #615 A = [[9.9424095]]\n",
      "Loss = 0.61600435\n",
      "Step #620 A = [[9.971267]]\n",
      "Loss = 0.50873756\n",
      "Step #625 A = [[9.975098]]\n",
      "Loss = 0.85608923\n",
      "Step #630 A = [[9.976403]]\n",
      "Loss = 0.64081323\n",
      "Step #635 A = [[9.95584]]\n",
      "Loss = 1.051618\n",
      "Step #640 A = [[9.949765]]\n",
      "Loss = 0.7069519\n",
      "Step #645 A = [[9.944663]]\n",
      "Loss = 0.3948201\n",
      "Step #650 A = [[9.945483]]\n",
      "Loss = 0.5211317\n",
      "Step #655 A = [[9.940672]]\n",
      "Loss = 0.8798598\n",
      "Step #660 A = [[9.96407]]\n",
      "Loss = 0.59336346\n",
      "Step #665 A = [[9.923197]]\n",
      "Loss = 0.8221324\n",
      "Step #670 A = [[9.928289]]\n",
      "Loss = 0.36676815\n",
      "Step #675 A = [[9.934535]]\n",
      "Loss = 0.593515\n",
      "Step #680 A = [[9.931093]]\n",
      "Loss = 0.4156692\n",
      "Step #685 A = [[9.965979]]\n",
      "Loss = 0.40801263\n",
      "Step #690 A = [[9.952558]]\n",
      "Loss = 0.62863475\n",
      "Step #695 A = [[9.9379]]\n",
      "Loss = 0.9665991\n",
      "Step #700 A = [[9.914332]]\n",
      "Loss = 0.97803706\n",
      "Step #705 A = [[9.939514]]\n",
      "Loss = 0.7840303\n",
      "Step #710 A = [[9.957402]]\n",
      "Loss = 0.58899575\n",
      "Step #715 A = [[9.950137]]\n",
      "Loss = 0.8216754\n",
      "Step #720 A = [[9.949811]]\n",
      "Loss = 1.4173073\n",
      "Step #725 A = [[9.950384]]\n",
      "Loss = 0.7207115\n",
      "Step #730 A = [[9.925174]]\n",
      "Loss = 0.66313255\n",
      "Step #735 A = [[9.906852]]\n",
      "Loss = 1.101166\n",
      "Step #740 A = [[9.910858]]\n",
      "Loss = 0.53477\n",
      "Step #745 A = [[9.939148]]\n",
      "Loss = 0.98193395\n",
      "Step #750 A = [[9.941027]]\n",
      "Loss = 0.58386034\n",
      "Step #755 A = [[9.967744]]\n",
      "Loss = 0.7746091\n",
      "Step #760 A = [[9.9625435]]\n",
      "Loss = 0.6345056\n",
      "Step #765 A = [[9.93454]]\n",
      "Loss = 0.6930193\n",
      "Step #770 A = [[9.953366]]\n",
      "Loss = 0.6241763\n",
      "Step #775 A = [[9.966525]]\n",
      "Loss = 0.5055995\n",
      "Step #780 A = [[9.984459]]\n",
      "Loss = 0.7395419\n",
      "Step #785 A = [[9.991715]]\n",
      "Loss = 0.68269044\n",
      "Step #790 A = [[9.991279]]\n",
      "Loss = 0.5894816\n",
      "Step #795 A = [[9.982869]]\n",
      "Loss = 0.6686833\n",
      "Step #800 A = [[9.985155]]\n",
      "Loss = 0.32951373\n",
      "Step #805 A = [[10.007973]]\n",
      "Loss = 0.7266242\n",
      "Step #810 A = [[10.000111]]\n",
      "Loss = 1.1625544\n",
      "Step #815 A = [[9.995809]]\n",
      "Loss = 0.30758852\n",
      "Step #820 A = [[9.991228]]\n",
      "Loss = 0.6260644\n",
      "Step #825 A = [[9.986055]]\n",
      "Loss = 0.45767093\n",
      "Step #830 A = [[9.959644]]\n",
      "Loss = 0.794966\n",
      "Step #835 A = [[9.967467]]\n",
      "Loss = 0.6676713\n",
      "Step #840 A = [[9.968903]]\n",
      "Loss = 0.8547473\n",
      "Step #845 A = [[9.969646]]\n",
      "Loss = 0.95647985\n",
      "Step #850 A = [[9.966583]]\n",
      "Loss = 0.32744926\n",
      "Step #855 A = [[9.962594]]\n",
      "Loss = 0.60409653\n",
      "Step #860 A = [[9.949114]]\n",
      "Loss = 0.6122182\n",
      "Step #865 A = [[9.968664]]\n",
      "Loss = 0.6486831\n",
      "Step #870 A = [[9.967726]]\n",
      "Loss = 0.3919027\n",
      "Step #875 A = [[9.940871]]\n",
      "Loss = 0.54230464\n",
      "Step #880 A = [[9.952172]]\n",
      "Loss = 0.3957476\n",
      "Step #885 A = [[9.943618]]\n",
      "Loss = 0.90818006\n",
      "Step #890 A = [[9.9637165]]\n",
      "Loss = 0.6032174\n",
      "Step #895 A = [[9.97707]]\n",
      "Loss = 0.7394868\n",
      "Step #900 A = [[9.976792]]\n",
      "Loss = 0.795064\n",
      "Step #905 A = [[9.967971]]\n",
      "Loss = 0.7842943\n",
      "Step #910 A = [[9.984326]]\n",
      "Loss = 0.69970435\n",
      "Step #915 A = [[9.986333]]\n",
      "Loss = 0.60370684\n",
      "Step #920 A = [[9.972017]]\n",
      "Loss = 0.46951827\n",
      "Step #925 A = [[9.96851]]\n",
      "Loss = 0.798988\n",
      "Step #930 A = [[9.945909]]\n",
      "Loss = 0.3080077\n",
      "Step #935 A = [[9.938973]]\n",
      "Loss = 0.809728\n",
      "Step #940 A = [[9.946122]]\n",
      "Loss = 0.93400365\n",
      "Step #945 A = [[9.941921]]\n",
      "Loss = 0.98762864\n",
      "Step #950 A = [[9.942985]]\n",
      "Loss = 0.69032377\n",
      "Step #955 A = [[9.95203]]\n",
      "Loss = 0.7130558\n",
      "Step #960 A = [[9.957391]]\n",
      "Loss = 0.90317726\n",
      "Step #965 A = [[9.980583]]\n",
      "Loss = 0.84983027\n",
      "Step #970 A = [[9.977615]]\n",
      "Loss = 1.1895676\n",
      "Step #975 A = [[9.972951]]\n",
      "Loss = 0.87965214\n",
      "Step #980 A = [[9.99023]]\n",
      "Loss = 0.8310793\n",
      "Step #985 A = [[9.974048]]\n",
      "Loss = 0.8422203\n",
      "Step #990 A = [[9.982633]]\n",
      "Loss = 0.68580973\n",
      "Step #995 A = [[9.934762]]\n",
      "Loss = 0.58957076\n",
      "Step #1000 A = [[9.945302]]\n",
      "Loss = 0.45375958\n",
      "Step #1005 A = [[9.950709]]\n",
      "Loss = 0.8217405\n",
      "Step #1010 A = [[9.967096]]\n",
      "Loss = 0.8577725\n",
      "Step #1015 A = [[9.975599]]\n",
      "Loss = 0.69945985\n",
      "Step #1020 A = [[9.974273]]\n",
      "Loss = 1.1592748\n",
      "Step #1025 A = [[9.984341]]\n",
      "Loss = 0.56995976\n",
      "Step #1030 A = [[9.979164]]\n",
      "Loss = 0.8953079\n",
      "Step #1035 A = [[9.979981]]\n",
      "Loss = 1.2347304\n",
      "Step #1040 A = [[9.9585285]]\n",
      "Loss = 0.48432025\n",
      "Step #1045 A = [[9.958137]]\n",
      "Loss = 0.38979495\n",
      "Step #1050 A = [[9.988583]]\n",
      "Loss = 0.67752254\n",
      "Step #1055 A = [[9.944541]]\n",
      "Loss = 0.90429896\n",
      "Step #1060 A = [[9.957901]]\n",
      "Loss = 0.9508368\n",
      "Step #1065 A = [[9.970957]]\n",
      "Loss = 0.8511802\n",
      "Step #1070 A = [[9.976078]]\n",
      "Loss = 0.83740175\n",
      "Step #1075 A = [[10.006083]]\n",
      "Loss = 0.60823804\n",
      "Step #1080 A = [[10.007319]]\n",
      "Loss = 0.77695\n",
      "Step #1085 A = [[10.03001]]\n",
      "Loss = 0.77212185\n",
      "Step #1090 A = [[10.020472]]\n",
      "Loss = 0.8320305\n",
      "Step #1095 A = [[9.988983]]\n",
      "Loss = 1.0287573\n",
      "Step #1100 A = [[9.983253]]\n",
      "Loss = 1.1658013\n"
     ]
    }
   ],
   "source": [
    "loss_batch = []\n",
    "for i in range(1100):\n",
    "    rand_index = np.random.choice(100, size = batch_size)\n",
    "    rand_x = np.transpose([x_vals[rand_index]])\n",
    "    rand_y = np.transpose([y_vals[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target : rand_y})\n",
    "    if (i+1)%5==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        print('Loss = ' + str(temp_loss))\n",
    "        loss_batch.append(temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-11T11:29:27.875188Z",
     "start_time": "2019-04-11T11:29:27.713360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, 1100, 5), loss_stochastic, 'b-', label='Stochastic Loss')\n",
    "plt.plot(range(0, 1100, 5), loss_batch, 'r--', label='Batch Loss, size=20')\n",
    "plt.legend(loc='upper right', prop={'size': 11})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
